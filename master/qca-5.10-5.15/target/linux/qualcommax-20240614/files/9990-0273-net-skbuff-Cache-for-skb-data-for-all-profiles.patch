From aef6fe6fba93af65b66354aa7ad463cf370723c0 Mon Sep 17 00:00:00 2001
From: Sneha Maganahalli <quic_smaganah@quicinc.com>
Date: Fri, 4 Feb 2022 14:29:37 +0530
Subject: [PATCH 273/281] net: skbuff: Cache for skb->data for all profiles.

Cache for skb->data for all profiles.

Change-Id: Ib84a1b0c037bc27febb24edbee91ffe6427d528d
Signed-off-by: Sneha Maganahalli <quic_smaganah@quicinc.com>
---
 net/core/skbuff.c | 34 +++++++++++++++++++++++-----------
 1 file changed, 23 insertions(+), 11 deletions(-)

--- a/net/core/skbuff.c
+++ b/net/core/skbuff.c
@@ -84,10 +84,29 @@
 #include "dev.h"
 #include "sock_destructor.h"
 
-
-#if defined(CONFIG_SKB_FIXED_SIZE_2K) && !defined(__LP64__)
 struct kmem_cache *skb_data_cache;
-#define SKB_DATA_CACHE_SIZE	2176
+
+/*
+ * For low memory profile, NSS_SKB_FIXED_SIZE_2K is enabled and
+ * CONFIG_SKB_RECYCLER is disabled. For premium and enterprise profile
+ * CONFIG_SKB_RECYCLER is enabled and NSS_SKB_FIXED_SIZE_2K is disabled.
+ * Irrespective of NSS_SKB_FIXED_SIZE_2K enabled/disabled, the
+ * CONFIG_SKB_RECYCLER and __LP64__ determines the value of SKB_DATA_CACHE_SIZE
+ */
+#if defined(CONFIG_SKB_RECYCLER)
+/*
+ * 2688 for 64bit arch, 2624 for 32bit arch
+ */
+#define SKB_DATA_CACHE_SIZE (SKB_DATA_ALIGN(SKB_RECYCLE_SIZE + NET_SKB_PAD) + SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))
+#else
+/*
+ * 2368 for 64bit arch, 2176 for 32bit arch
+ */
+#if defined(__LP64__)
+#define SKB_DATA_CACHE_SIZE ((SKB_DATA_ALIGN(1984 + NET_SKB_PAD)) + SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))
+#else
+#define SKB_DATA_CACHE_SIZE ((SKB_DATA_ALIGN(1856 + NET_SKB_PAD)) + SKB_DATA_ALIGN(sizeof(struct skb_shared_info)))
+#endif
 #endif
 
 struct kmem_cache *skbuff_head_cache __ro_after_init;
@@ -450,14 +469,12 @@ static void *kmalloc_reserve(unsigned in
 	 * Try a regular allocation, when that fails and we're not entitled
 	 * to the reserves, fail.
 	 */
-#if defined(CONFIG_SKB_FIXED_SIZE_2K) && !defined(__LP64__)
 	if (obj_size > SZ_2K && obj_size <= SKB_DATA_CACHE_SIZE)
 		obj = kmem_cache_alloc_node(skb_data_cache,
 						flags | __GFP_NOMEMALLOC | __GFP_NOWARN,
 						node);
 	else
-#endif
-	obj = kmalloc_node_track_caller(obj_size,
+		obj = kmalloc_node_track_caller(obj_size,
 					flags | __GFP_NOMEMALLOC | __GFP_NOWARN,
 					node);
 	if (obj || !(gfp_pfmemalloc_allowed(flags)))
@@ -465,11 +482,9 @@ static void *kmalloc_reserve(unsigned in
 
 	/* Try again but now we are using pfmemalloc reserves */
 	ret_pfmemalloc = true;
-#if defined(CONFIG_SKB_FIXED_SIZE_2K) && !defined(__LP64__)
 	if (obj_size > SZ_2K && obj_size <= SKB_DATA_CACHE_SIZE)
 		obj = kmem_cache_alloc_node(skb_data_cache, flags, node);
 	else
-#endif
 		obj = kmalloc_node_track_caller(obj_size, flags, node);
 
 out:
@@ -4575,13 +4590,10 @@ static void skb_extensions_init(void) {}
 
 void __init skb_init(void)
 {
-
-#if defined(CONFIG_SKB_FIXED_SIZE_2K) && !defined(__LP64__)
 	skb_data_cache = kmem_cache_create_usercopy("skb_data_cache",
 						SKB_DATA_CACHE_SIZE,
-						0, 0, 0, SKB_DATA_CACHE_SIZE,
+						0, SLAB_PANIC, 0, SKB_DATA_CACHE_SIZE,
 						NULL);
-#endif
 
 	skbuff_head_cache = kmem_cache_create_usercopy("skbuff_head_cache",
 					      sizeof(struct sk_buff),
