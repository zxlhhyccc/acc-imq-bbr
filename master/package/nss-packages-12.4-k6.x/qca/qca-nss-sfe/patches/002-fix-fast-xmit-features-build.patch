--- a/sfe_ipv4_esp.c
+++ b/sfe_ipv4_esp.c
@@ -331,7 +331,7 @@ int sfe_ipv4_recv_esp(struct sfe_ipv4 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv4_pppoe_br.c
+++ b/sfe_ipv4_pppoe_br.c
@@ -213,7 +213,7 @@ int sfe_ipv4_recv_pppoe_bridge(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv4_multicast.c
+++ b/sfe_ipv4_multicast.c
@@ -166,7 +166,7 @@ int sfe_ipv4_forward_multicast(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv4_tcp.c
+++ b/sfe_ipv4_tcp.c
@@ -861,10 +861,8 @@ int sfe_ipv4_recv_tcp(struct sfe_ipv4 *s
 	 */
 	if (likely(fast_xmit)) {
 		if (likely(!skb_is_gso(skb))) {
-			if (likely(dev_fast_xmit(skb, xmit_dev, features))) {
 				this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 				return 1;
-			}
 		} else {
 			cm->flags &= ~SFE_IPV4_CONNECTION_MATCH_FLAG_FAST_XMIT;
 			DEBUG_TRACE("%px: fast xmit disabled for xmit dev %s", skb, xmit_dev->name);
@@ -890,7 +888,7 @@ int sfe_ipv4_recv_tcp(struct sfe_ipv4 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
         if (cm->flags & SFE_IPV4_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv4_udp.c
+++ b/sfe_ipv4_udp.c
@@ -680,7 +680,7 @@ int sfe_ipv4_recv_udp(struct sfe_ipv4 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
@@ -704,7 +704,7 @@ int sfe_ipv4_recv_udp(struct sfe_ipv4 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV4_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv6_multicast.c
+++ b/sfe_ipv6_multicast.c
@@ -164,7 +164,7 @@ int sfe_ipv6_forward_multicast(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6.c
+++ b/sfe_ipv6.c
@@ -1034,7 +1034,7 @@ static bool sfe_ipv6_is_local_ip(struct
 	struct in6_addr ip_addr;
 	memcpy(ip_addr.s6_addr, addr, 16);
 
-#if (LINUX_VERSION_CODE < KERNEL_VERSION(6, 1, 0))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 15, 0))
 	dev = ipv6_dev_find(&init_net, &ip_addr, 1);
 #else
 	dev = ipv6_dev_find(&init_net, &ip_addr, NULL);
--- a/sfe_ipv6_esp.c
+++ b/sfe_ipv6_esp.c
@@ -311,7 +311,7 @@ int sfe_ipv6_recv_esp(struct sfe_ipv6 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6_pppoe_br.c
+++ b/sfe_ipv6_pppoe_br.c
@@ -216,7 +216,7 @@ int sfe_ipv6_recv_pppoe_bridge(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6_tcp.c
+++ b/sfe_ipv6_tcp.c
@@ -809,10 +809,8 @@ int sfe_ipv6_recv_tcp(struct sfe_ipv6 *s
 	 */
 	if (likely(fast_xmit)) {
 		if (likely(!skb_is_gso(skb))) {
-			if (likely(dev_fast_xmit(skb, xmit_dev, features))) {
 				this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 				return 1;
-			}
 		} else {
 			cm->flags &= ~SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_XMIT;
 			DEBUG_TRACE("%px: fast xmit disabled for xmit dev %s", skb, xmit_dev->name);
@@ -838,7 +836,7 @@ int sfe_ipv6_recv_tcp(struct sfe_ipv6 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv6_udp.c
+++ b/sfe_ipv6_udp.c
@@ -655,7 +655,7 @@ int sfe_ipv6_recv_udp(struct sfe_ipv6 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
@@ -679,7 +679,7 @@ int sfe_ipv6_recv_udp(struct sfe_ipv6 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
