--- a/sfe_ipv4_esp.c
+++ b/sfe_ipv4_esp.c
@@ -331,7 +331,7 @@ int sfe_ipv4_recv_esp(struct sfe_ipv4 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv4_pppoe_br.c
+++ b/sfe_ipv4_pppoe_br.c
@@ -213,7 +213,7 @@ int sfe_ipv4_recv_pppoe_bridge(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv4_multicast.c
+++ b/sfe_ipv4_multicast.c
@@ -179,7 +179,7 @@ int sfe_ipv4_forward_multicast(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv4_tcp.c
+++ b/sfe_ipv4_tcp.c
@@ -887,10 +887,8 @@ int sfe_ipv4_recv_tcp(struct sfe_ipv4 *s
 	 */
 	if (likely(fast_xmit)) {
 		if (likely(!skb_is_gso(skb))) {
-			if (likely(dev_fast_xmit(skb, xmit_dev, features))) {
 				this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 				return 1;
-			}
 		} else {
 			cm->flags &= ~SFE_IPV4_CONNECTION_MATCH_FLAG_FAST_XMIT;
 			DEBUG_TRACE("%px: fast xmit disabled for xmit dev %s", skb, xmit_dev->name);
@@ -912,7 +910,7 @@ int sfe_ipv4_recv_tcp(struct sfe_ipv4 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
         if (cm->flags & SFE_IPV4_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv4_udp.c
+++ b/sfe_ipv4_udp.c
@@ -707,7 +707,7 @@ int sfe_ipv4_recv_udp(struct sfe_ipv4 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
@@ -727,7 +727,7 @@ int sfe_ipv4_recv_udp(struct sfe_ipv4 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV4_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv6_multicast.c
+++ b/sfe_ipv6_multicast.c
@@ -179,7 +179,7 @@ int sfe_ipv6_forward_multicast(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6.c
+++ b/sfe_ipv6.c
@@ -1081,7 +1081,7 @@ static bool sfe_ipv6_is_local_ip(struct
 	struct in6_addr ip_addr;
 	memcpy(ip_addr.s6_addr, addr, 16);
 
-#if (LINUX_VERSION_CODE < KERNEL_VERSION(6, 1, 0))
+#if (LINUX_VERSION_CODE < KERNEL_VERSION(5, 15, 0))
 	dev = ipv6_dev_find(&init_net, &ip_addr, 1);
 #else
 	dev = ipv6_dev_find(&init_net, &ip_addr, NULL);
--- a/sfe_ipv6_esp.c
+++ b/sfe_ipv6_esp.c
@@ -311,7 +311,7 @@ int sfe_ipv6_recv_esp(struct sfe_ipv6 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6_pppoe_br.c
+++ b/sfe_ipv6_pppoe_br.c
@@ -216,7 +216,7 @@ int sfe_ipv6_recv_pppoe_bridge(struct sf
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6_tcp.c
+++ b/sfe_ipv6_tcp.c
@@ -839,10 +839,8 @@ int sfe_ipv6_recv_tcp(struct sfe_ipv6 *s
 	 */
 	if (likely(fast_xmit)) {
 		if (likely(!skb_is_gso(skb))) {
-			if (likely(dev_fast_xmit(skb, xmit_dev, features))) {
 				this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 				return 1;
-			}
 		} else {
 			cm->flags &= ~SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_XMIT;
 			DEBUG_TRACE("%px: fast xmit disabled for xmit dev %s", skb, xmit_dev->name);
@@ -864,7 +862,7 @@ int sfe_ipv6_recv_tcp(struct sfe_ipv6 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv6_udp.c
+++ b/sfe_ipv6_udp.c
@@ -689,7 +689,7 @@ int sfe_ipv6_recv_udp(struct sfe_ipv6 *s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
@@ -709,7 +709,7 @@ int sfe_ipv6_recv_udp(struct sfe_ipv6 *s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
--- a/sfe_ipv6_etherip.c
+++ b/sfe_ipv6_etherip.c
@@ -290,7 +290,7 @@ int sfe_ipv6_recv_etherip(struct sfe_ipv6 *si, struct sk_buff *skb, struct net_d
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
--- a/sfe_ipv6_frag.c
+++ b/sfe_ipv6_frag.c
@@ -795,7 +795,7 @@ static int sfe_ipv6_frag_udp_forward(struct sfe_ipv6 *si, struct sk_buff *skb, s
 	 * We do per packet condition check before we could fast xmit the
 	 * packet.
 	 */
-	if (likely(fast_xmit && dev_fast_xmit(skb, xmit_dev, features))) {
+	if (likely(fast_xmit)) {
 		this_cpu_inc(si->stats_pcpu->packets_fast_xmited64);
 		return 1;
 	}
@@ -816,7 +816,7 @@ static int sfe_ipv6_frag_udp_forward(struct sfe_ipv6 *si, struct sk_buff *skb, s
 	 * check if fast qdisc xmit is enabled and send the packet on its way.
 	 */
 	if (cm->flags & SFE_IPV6_CONNECTION_MATCH_FLAG_FAST_QDISC_XMIT) {
-		if (likely(dev_fast_xmit_qdisc(skb, xmit_dev, cm->qdisc_xmit_dev))) {
+		if (likely(fast_xmit)) {
 			this_cpu_inc(si->stats_pcpu->packets_fast_qdisc_xmited64);
 			return 1;
 		}
